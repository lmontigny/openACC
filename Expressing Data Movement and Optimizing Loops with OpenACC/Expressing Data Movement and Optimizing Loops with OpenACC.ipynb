{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expressing Data Movement and Optimizing Loops with OpenACC\n",
    "\n",
    "Lab written by Jeff Larkin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following timer counts down to a five minute warning before the lab instance shuts down.  You should get a pop up at the five minute warning reminding you to save your work!  If you are about to run out of time, please see the [Post-Lab](#Post-Lab-Summary) section for saving this lab to view offline later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe id=\"timer\" src=\"timer/timer.html\" width=\"100%\" height=\"120px\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Before we begin, let's verify [WebSockets](http://en.wikipedia.org/wiki/WebSocket) are working on your system.  To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see some output returned below the grey cell.  If not, please consult the [Self-paced Lab Troubleshooting FAQ](https://developer.nvidia.com/self-paced-labs-faq#Troubleshooting) to debug the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer should be three: 3\n"
     ]
    }
   ],
   "source": [
    "print \"The answer should be three: \" + str(1+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute the cell below to display information about the GPUs running on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  8 10:50:15 2017       \r\n",
      "+------------------------------------------------------+                       \r\n",
      "| NVIDIA-SMI 352.68     Driver Version: 352.68         |                       \r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GRID K520           On   | 0000:00:03.0     Off |                  N/A |\r\n",
      "| N/A   23C    P8    17W / 125W |     11MiB /  4095MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Your Lab Instance\n",
    "\n",
    "You are required to connect to the lab instance over SSH - much like you would when working on a real system.  You can do this by:\n",
    "* Using a local SSH client, connect to **ec2-54-144-47-202.compute-1.amazonaws.com** with username **ubuntu** and password **2Wsm5QSK**\n",
    "* If you don't have an SSH client installed, you can use the provided <a href=\"ssh\" target=\"_blank\">browser-based client.</a> and the same username and password as above.  \n",
    "  * **NOTE**: If you right-click in the browser-based client, you can select \"Paste from browser\" to easily copy & paste in the password.\n",
    "\n",
    "Once connected, please proceed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the previous lab we performed the first two steps of the OpenACC programming cycle, Identify and \n",
    "Express Parallelism, on a sample code. CUDA Unified Memory was used to allow us to ignore the seperate \n",
    "memories between the CPU and GPU. In this lab we will continue to use this code and apply the final two\n",
    "steps of the process, Express Data Movement and Optimize Loops. Versions of the code\n",
    "have been provided in C99 (directory `/home/ubuntu/c99`) and Fortran 90 (directory `/home/ubuntu/f90`). \n",
    "The `nano`, `vim`, and `emacs` file editors are all available to use during this lab. \n",
    "If you are not experienced with Linux text editors, `nano` is the simplest choice. Intermediate code (after\n",
    "applying step 1) and the final solution are provided for each code.\n",
    "\n",
    "![Lecture 3 steps: Express Data Movement and Optimize Loops](files/Lecture-3-Steps.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - Building the code\n",
    "\n",
    "Makefiles have been provided for building both the C and Fortran versions of the code. Change directory to your language of choice and run the `make` command to build the code.\n",
    "\n",
    "### C/C++\n",
    "\n",
    "```\n",
    "$ cd ~/c99\n",
    "$ make\n",
    "```\n",
    "    \n",
    "### Fortran\n",
    "\n",
    "```\n",
    "$ cd ~/f90\n",
    "$ make\n",
    "```\n",
    "    \n",
    "This will build an executable named `cg` that you can run with the `./cg` command. You may change the options passed to the compiler by modifying the `CFLAGS` variable in `c99/Makefile` or `FCFLAGS` in `f90/Makefile`. You should not need to modify anything in the Makefile except these compiler flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Step 1 - Express Data Movement\n",
    "\n",
    "In the previous lab we used CUDA Unified Memory, which we enabled with the\n",
    "`ta=tesla:managed` compiler option, to eliminate the need for data management\n",
    "directives. Replace this compiler flag in the Makefile with `-ta=tesla` and try\n",
    "to rebuild the code.\n",
    "\n",
    "### C/C++\n",
    "With the managed memory option removed the C/C++ version will fail to build\n",
    "because the compiler will not be able to determine the sizes of some of the\n",
    "arrays used in compute regions. You will see an error like the one below.\n",
    "\n",
    "    PGCC-S-0155-Compiler failed to translate accelerator region (see -Minfo messages): Could not find allocated-variable index for symbol (main.cpp: 15)\n",
    "\n",
    "### Fortran\n",
    "The Fortran version of the code will build successfully and run, however the\n",
    "tolerance value will be incorrect with the managed memory option removed.\n",
    "\n",
    "    $ ./cg\n",
    "     Rows:      8120601 nnz:    218535025\n",
    "     Iteration:  0 Tolerance: 4.006700E+08\n",
    "     Iteration: 10 Tolerance: 4.006700E+08\n",
    "     Iteration: 20 Tolerance: 4.006700E+08\n",
    "     Iteration: 30 Tolerance: 4.006700E+08\n",
    "     Iteration: 40 Tolerance: 4.006700E+08\n",
    "     Iteration: 50 Tolerance: 4.006700E+08\n",
    "     Iteration: 60 Tolerance: 4.006700E+08\n",
    "     Iteration: 70 Tolerance: 4.006700E+08\n",
    "     Iteration: 80 Tolerance: 4.006700E+08\n",
    "     Iteration: 90 Tolerance: 4.006700E+08\n",
    "      Total Iterations:          100\n",
    "\n",
    "---\n",
    "\n",
    "We can correct both of these problems by explicitly declaring the data movement for the\n",
    "arrays that we need on the GPU. In the associated lecture we discussed the\n",
    "OpenACC structured `data` directive and the unstructured `enter data` and `exit data` \n",
    "directives. Either approaced can be used to express the data locality in\n",
    "this code, but the unstructured directives are probably cleaner to use.\n",
    "\n",
    "### C/C++\n",
    "In the `allocate_3d_poisson_matrix` function in matrix.h, add the following two\n",
    "directives to the end of the function.\n",
    "\n",
    "\n",
    "    #pragma acc enter data copyin(A)\n",
    "    #pragma acc enter data copyin(A.row_offsets[:num_rows+1],A.cols[:nnz],A.coefs[:nnz])\n",
    "\n",
    "The first directive copies the A structure to the GPU, which includes the\n",
    "`num_rows` member and the pointers for the three member arrays. The second\n",
    "directive then copies the three arrays to the device. Now that we've created\n",
    "space on the GPU for these arrays, it's necessary to clean up the space when\n",
    "we're done. In the `free_matrix` function, add the following directives\n",
    "immediately before the calls to `free`.\n",
    "\n",
    "\n",
    "    #pragma acc exit data delete(A.row_offsets,A.cols,A.coefs)\n",
    "    #pragma acc exit data delete(A)\n",
    "      free(row_offsets);\n",
    "      free(cols);\n",
    "      free(coefs);\n",
    "\n",
    "Notice that we are performing the operations in the reverse order. First we are\n",
    "deleting the 3 member arrays from the device, then we are deleting the\n",
    "structure containing those arrays. It's also critical that we place our pragmas\n",
    "*before* the arrays are freed on the host, otherwise the `exit data` directives\n",
    "will fail.\n",
    "\n",
    "Now go into `vector.h` and do the same thing in `allocate_vector` and\n",
    "`free_vector` with the structure `v` and its member array `v.coefs`. Because \n",
    "we are copying the arrays to the device before they have been populated with \n",
    "data, use the `create` data clause, rather than `copyin`.\n",
    "\n",
    "If you try\n",
    "to build again at this point, the code will still fail to build because we\n",
    "haven't told our compute regions that the data is already present on the\n",
    "device, so the compiler is still trying to determine the array sizes itself.\n",
    "Now go to the compute regions (`kernels` or `parallel loop`) in\n",
    "`matrix_functions.h` and `vector_functions.h` and use the `present` clause to\n",
    "inform the compiler that the arrays are already on the device. Below is an\n",
    "example for `matvec`.\n",
    "\n",
    "    #pragma acc kernels present(row_offsets,cols,Acoefs,xcoefs,ycoefs)\n",
    "\n",
    "Once you have added the `present` clause to all three compute regions, the \n",
    "application should now build and run on the GPU, but is no longer getting\n",
    "correct results. This is because we've put the arrays on the device, but we've\n",
    "failed to copy the input data into these arrays. Add the following directive to\n",
    "the end of `initialize_vector` function.\n",
    "\n",
    "    #pragma acc update device(v.coefs[:v.n])\n",
    "\n",
    "This will copy the data now in the host array to the GPU\n",
    "copy of the array. With this data now correctly copied to the GPU, the code\n",
    "should run to completion and give the same results as before.\n",
    "\n",
    "### Fortran\n",
    "To make the application return correct answers again, it will be necessary to\n",
    "add explicit data management directives. This could be done using either the\n",
    "structured `data` directives or unstructured `enter data` and `exit data`\n",
    "directives, as discussed in the lecture. Since this program has clear routines\n",
    "for allocating and initializing the data structures and also deallocating,\n",
    "we'll use the unstructured directives to make the code easy to understand.\n",
    "\n",
    "The `allocate_3d_poission_matrix` in matrix.F90 handles allocating and\n",
    "initializing the primary array. At the end of this routine, add the following\n",
    "directive for copying the three arrays in the matrix type to the device.\n",
    "\n",
    "    !$acc enter data copyin(arow_offsets,acols,acoefs)\n",
    "\n",
    "These three arrays can be copied in seperate `enter data` directives as well.\n",
    "Notice that because Fortran arrays are self-describing, it's unnecessary to\n",
    "provide the array bounds, although it would be safe to do so as well. Since\n",
    "we've allocated these arrays on the device, they should be removed from the\n",
    "device when we are done with them as well. In the `free_matrix` subroutine of\n",
    "matrix.F90 add the following directive.\n",
    "\n",
    "    !$acc exit data delete(arow_offsets,acols,acoefs)\n",
    "    deallocate(arow_offsets)\n",
    "    deallocate(acols)\n",
    "    deallocate(acoefs)\n",
    "\n",
    "Notice that the `exit data` directive appears before the `deallocate`\n",
    "statement. Because the OpenACC programming model assumes we always begin and\n",
    "end execution on the host, it's necessary to remove arrays from the device\n",
    "before freeing them on the host to avoid an error or crash. Now go add \n",
    "`enter data` and `exit data` directives to vector.F90 as well. Notice that the\n",
    "`allocate_vector` routine only allocates the array, but does not initialize it,\n",
    "so `copyin` may be replaced with `create` on the `enter data` directive.\n",
    "\n",
    "If we build and run the application at this point we should see our tolerance\n",
    "changing once again, but the answers will still be incorrect. Next let go to\n",
    "each compute directive (`kernels` or `parallel loop`) in matrix.F90 and\n",
    "vector.F90 and inform the compiler that the arrays used in those regions are\n",
    "already present on the device. Below is an example from matrix.F90.\n",
    "\n",
    "    !$acc kernels present(arow_offsets,acols,acoefs,x,y)\n",
    "\n",
    "At this point the compiler knows that it does not need to be concerned with\n",
    "data movement in our compute regions, but we're still getting the wrong answer.\n",
    "The last change we need to make is to make sure that we're copying the input\n",
    "data to the device before execution. In vector.F90 add the following directive\n",
    "to the end of `initialize_vector`.\n",
    "\n",
    "    vector(:) = value\n",
    "    !$acc update device(vector)\n",
    "\n",
    "Now that we have the correct input data on the device the code should run\n",
    "correctly once again.\n",
    "\n",
    "---\n",
    "\n",
    "*(NOTE for C/C++ and Fortran: One could also parallelize the loop in\n",
    "`initialize_vector` on the GPU, but we choose to use the `update` directive\n",
    "here to illustrate how this directive is used.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Optimize Loops - Vector Length\n",
    "\n",
    "Now that we're running on the GPU and getting correct answers , let's apply our\n",
    "knowledge of the code to help the compiler make better decisions about how to\n",
    "parallelize our loops. We know from the `allocate_3d_poission_matrix` routine\n",
    "that the most non-zero elements we'll have per row is 27. By examining the \n",
    "compiler output, as shown below, we know that the compiler chose a vector length\n",
    "of 128 for the `matvec` loops. This means that with\n",
    "the compiler-selected vector length of 128, 101 vector lanes (threads) will go\n",
    "unused. Let's tell the compiler to choose a better vector length for these\n",
    "loops.\n",
    "\n",
    "    matvec(const matrix &, const vector &, const vector &):\n",
    "          8, include \"matrix_functions.h\"\n",
    "              15, Generating present(row_offsets[:],cols[:],Acoefs[:],xcoefs[:],ycoefs[:])\n",
    "              16, Loop is parallelizable\n",
    "                  Accelerator kernel generated\n",
    "                  Generating Tesla code\n",
    "                  16, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
    "              20, Loop is parallelizable\n",
    "\n",
    "On an NVIDIA GPU the vector length must be a multiple of the *warp size* of the\n",
    "GPU, which on all NVIDIA GPUs to-date is 32. This means that the closest vector\n",
    "length we can choose is 32. Depending on whether the code uses `kernels` or\n",
    "`parallel loop`, we can specify the vector length one of two ways.\n",
    "\n",
    "### Kernels\n",
    "When using the `kernels` directive, the vector length is given by adding\n",
    "`vector(32)` to the loop we want to use as the `vector` loop. So for our\n",
    "`matvec` loops, we'd apply the vector length as shown below.\n",
    "\n",
    "#### C/C++\n",
    "    #pragma acc kernels present(row_offsets,cols,Acoefs,xcoefs,ycoefs)\n",
    "      {\n",
    "        for(int i=0;i<num_rows;i++) {\n",
    "          double sum=0;\n",
    "          int row_start=row_offsets[i];\n",
    "          int row_end=row_offsets[i+1];\n",
    "          #pragma acc loop device_type(nvidia) vector(32)\n",
    "          for(int j=row_start;j<row_end;j++) {\n",
    "            unsigned int Acol=cols[j];\n",
    "            double Acoef=Acoefs[j];\n",
    "            double xcoef=xcoefs[Acol];\n",
    "            sum+=Acoef*xcoef;\n",
    "          }\n",
    "          ycoefs[i]=sum;\n",
    "        }\n",
    "      }\n",
    "\n",
    "#### Fortran\n",
    "    !$acc kernels present(arow_offsets,acols,acoefs,x,y)\n",
    "    do i=1,a%num_rows\n",
    "      tmpsum = 0.0d0\n",
    "      row_start = arow_offsets(i)\n",
    "      row_end   = arow_offsets(i+1)-1\n",
    "      !$acc loop device_type(nvidia) vector(32)\n",
    "      do j=row_start,row_end\n",
    "        acol = acols(j)\n",
    "        acoef = acoefs(j)\n",
    "        xcoef = x(acol)\n",
    "        tmpsum = tmpsum + acoef*xcoef\n",
    "      enddo\n",
    "      y(i) = tmpsum\n",
    "    enddo\n",
    "    !$acc end kernels\n",
    "\n",
    "### Parallel Loop\n",
    "When using `parallel loop` the vector length is given at the top of the region,\n",
    "as shown below.\n",
    "\n",
    "#### C/C++\n",
    "    #pragma acc parallel loop present(row_offsets,cols,Acoefs,xcoefs,ycoefs) \\\n",
    "            device_type(nvidia) vector_length(32)\n",
    "      for(int i=0;i<num_rows;i++) {\n",
    "        double sum=0;\n",
    "        int row_start=row_offsets[i];\n",
    "        int row_end=row_offsets[i+1];\n",
    "    #pragma acc loop reduction(+:sum) device_type(nvidia) vector\n",
    "        for(int j=row_start;j<row_end;j++) {\n",
    "          unsigned int Acol=cols[j];\n",
    "          double Acoef=Acoefs[j];\n",
    "          double xcoef=xcoefs[Acol];\n",
    "          sum+=Acoef*xcoef;\n",
    "        }\n",
    "        ycoefs[i]=sum;\n",
    "      }\n",
    "\n",
    "#### Fortran\n",
    "    !$acc parallel loop private(tmpsum,row_start,row_end) &\n",
    "    !$acc& present(arow_offsets,acols,acoefs,x,y)         &\n",
    "    !$acc& device_type(nvidia) vector_length(32)\n",
    "    do i=1,a%num_rows\n",
    "      tmpsum = 0.0d0\n",
    "      row_start = arow_offsets(i)\n",
    "      row_end   = arow_offsets(i+1)-1\n",
    "      !$acc loop reduction(+:tmpsum) device_type(nvidia) vector\n",
    "      do j=row_start,row_end\n",
    "        acol = acols(j)\n",
    "        acoef = acoefs(j)\n",
    "        xcoef = x(acol)\n",
    "        tmpsum = tmpsum + acoef*xcoef\n",
    "      enddo\n",
    "      y(i) = tmpsum\n",
    "    enddo\n",
    "\n",
    "---\n",
    "\n",
    "Notice that the above code adds the `device_type(nvidia)` clause to the\n",
    "affected loops. Because we only want this optimization to be applied to NVIDIA\n",
    "GPUs, we've protected that optimization with a `device_type` clause and allowed\n",
    "the compiler to determine the best value on other platforms. Now that we've\n",
    "adjusted the vector length to fit the problem, let's profile the code again to\n",
    "see how well it's performing. Using Visual Profiler,\n",
    "let's see if we can find a way to further improve performance.\n",
    "\n",
    "The folders `intermediate.kernels` and `intermediate.parallel` contain the correct\n",
    "code for the end of this step. If you have any trouble, use the code in one of these\n",
    "folders to help yourself along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Optimize Loops - Profile The Application\n",
    "\n",
    "Just as in the last lab, we'll use the NVIDIA Visual Profiler to profile our\n",
    "application.\n",
    "\n",
    "- If you are doing this lab via qwikLABs, launch the NVIDIA Visual Profiler by following these steps:\n",
    " 1. First connect to the Ubuntu remote desktop. There are few ways to do this:\n",
    "   * Using the <a href=\"/vnc\" target=\"_blank\">browser-based VNC client</a> (easiest but lowest performance of the options)\n",
    "   * Connecting with a local VNC client to **ec2-54-144-47-202.compute-1.amazonaws.com** using password **2Wsm5QSK**\n",
    "   * Connecting with NoMachine 4.x or 5.x client to **ec2-54-144-47-202.compute-1.amazonaws.com** with username **ubuntu** and password **2Wsm5QSK** on port 4000 - the NX protocol (best performance of the options)\n",
    " 2. Once you're connected to the Ubuntu remote desktop, click the Ubuntu icon in the upper-left of the desktop, and type *nvvp* in the search box and hit enter.\n",
    " 3. After a short-time you will see the NVIDIA Visual Profiler application\n",
    "- If you are doing this lab on your own machine, either launch Visual Profiler\n",
    "  from its application link or via the `nvvp` command.\n",
    "\n",
    "Once Visual Profiler has started, create a new session by selecting *File -> New\n",
    "Session*. Then select the executable that you built by pressing the *Browse*\n",
    "button next to *File*, browse to your working directory, select the `cg`\n",
    "executable, and then press *Next*. On the next screen press *Finish*. Visual\n",
    "Profiler will run for several seconds to collect a GPU timeline and begin its\n",
    "*guided analysis*.\n",
    "\n",
    "In the lower left, press the \"Examine GPU Usage\" button. You may need to\n",
    "enlarge the bottom panel of the screen by grabbing just below the horizontal\n",
    "scroll bar at the middle of the window and dragging it up until the button is\n",
    "visial. After this runs, click on \"Examine Individual Kernels\" and select the\n",
    "top kernel in the table. After selecting the top kernel, press the \"Perform\n",
    "Kernel Analysis\" button to gather further performance information about this\n",
    "kernel and wait while Visual Profiler collects additional data ***(this make take\n",
    "several minutes)***. When this completes, press \"Perform Latency Analysis\". The \n",
    "screenshot below shows Visual Profiler at this step.\n",
    "\n",
    "![NVIDIA Visual Profiler Limited By Block Size](files/lab3-nvvp-block-limit.png)\n",
    "\n",
    "Visual Profiler is telling us that the performance of the matvec kernel is limited\n",
    "by the amount of parallelism in each gang (referred to as *\"block size\"* in CUDA). \n",
    "Scrolling down in the *Results* section \n",
    "I see that the *Occupancy* is 25%. Occupancy is a measure of how much parallelism \n",
    "is running on the GPU versus how much theoretically could be running. 25% occupancy\n",
    "indicates that resources are sitting idle due to the size of the blocks (OpenACC gangs).\n",
    "(***Note:*** *100% occupancy is not necessary for high performance, but occupancy below\n",
    "50% is frequently an indicator that optimization is possible)\n",
    "\n",
    "Scrolling further down in the *Results* section we reach the *Block Limit* metric, \n",
    "which will be highlighted in red. This is shown in the screenshot below.\n",
    "\n",
    "![NVIDIA Visual Profiler Occupancy Screenshot](files/lab3-nvvp-occupancy.png)\n",
    " \n",
    "This table is showing us that the GPU *streaming multiprocessor (SM)* can theoretically\n",
    "run 64 *warps* (groups of 32 threads), but only has 16 to run. Looking at the *Warps/Block*\n",
    "and *Threads/Block* rows of the table, we see that each block contains 1 warp, or 32 threads, \n",
    "although it could run many more. This is because we've told the compiler to use a vector\n",
    "length of 32. As a reminder, in OpenACC many *gangs* run independently of each other, each gang\n",
    "has 1 or more *workers*, each of which operates on a *vector*. With a vector length of 32, \n",
    "we'll need to add workers in order to increase the work per gang. Now we need to inform the\n",
    "compiler to give each gang more work by using *worker* parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Optimize Loops - Increase Parallelism\n",
    "To increase the parallelism in each OpenACC gang, we'll use the worker level of\n",
    "parallelism to operate on multiple vectors within each gang. On an NVIDIA GPU\n",
    "the *vector length X number of workers* must be a multiple of 32 and no larger\n",
    "than 1024, so let's experiment with increasing the number of workers. From just\n",
    "1 worker up to 32. We want the outermost loop to be divided among gangs and\n",
    "workers, so we'll specify that it is an gang *and* worker loop. By only\n",
    "specifying the number of workers, we allow the compiler to generate enough\n",
    "gangs to use up the rest of the loop iterations applying worker parallelism. \n",
    "\n",
    "\n",
    "### Kernels\n",
    "When using the `kernels` directive, use the `loop` directive to specify that\n",
    "the outer loop should be a *gang* and *worker* loop with 32 workers as shown\n",
    "below. Experiment with the number of workers to find the best value.\n",
    "\n",
    "#### C/C++\n",
    "    #pragma acc kernels present(row_offsets,cols,Acoefs,xcoefs,ycoefs)\n",
    "      {\n",
    "    #pragma acc loop device_type(nvidia) gang worker(32)\n",
    "        for(int i=0;i<num_rows;i++) {\n",
    "          double sum=0;\n",
    "          int row_start=row_offsets[i];\n",
    "          int row_end=row_offsets[i+1];\n",
    "          #pragma acc loop device_type(nvidia) vector(32)\n",
    "          for(int j=row_start;j<row_end;j++) {\n",
    "            unsigned int Acol=cols[j];\n",
    "            double Acoef=Acoefs[j];\n",
    "            double xcoef=xcoefs[Acol];\n",
    "            sum+=Acoef*xcoef;\n",
    "          }\n",
    "          ycoefs[i]=sum;\n",
    "        }\n",
    "      }\n",
    "\n",
    "#### Fortran\n",
    "    !$acc kernels present(arow_offsets,acols,acoefs,x,y)\n",
    "    !$acc loop device_type(nvidia) gang worker(32)\n",
    "    do i=1,a%num_rows\n",
    "      tmpsum = 0.0d0\n",
    "      row_start = arow_offsets(i)\n",
    "      row_end   = arow_offsets(i+1)-1\n",
    "      !$acc loop device_type(nvidia) vector(32)\n",
    "      do j=row_start,row_end\n",
    "        acol = acols(j)\n",
    "        acoef = acoefs(j)\n",
    "        xcoef = x(acol)\n",
    "        tmpsum = tmpsum + acoef*xcoef\n",
    "      enddo\n",
    "      y(i) = tmpsum\n",
    "    enddo\n",
    "    !$acc end kernels\n",
    "\n",
    "### Parallel Loop\n",
    "When using the `parallel loop` directive, use `gang` and `worker` to specify\n",
    "that the outer loop should be a *gang* and *worker* loop and then add\n",
    "`num_workers(32)` to specify 32 workers, as shown below. Experiment with \n",
    "the number of workers to find the best value.\n",
    "\n",
    "#### C/C++\n",
    "    #pragma acc parallel loop present(row_offsets,cols,Acoefs,xcoefs,ycoefs) \\\n",
    "            device_type(nvidia) gang worker vector_length(32) num_workers(32)\n",
    "      for(int i=0;i<num_rows;i++) {\n",
    "        double sum=0;\n",
    "        int row_start=row_offsets[i];\n",
    "        int row_end=row_offsets[i+1];\n",
    "    #pragma acc loop reduction(+:sum) device_type(nvidia) vector\n",
    "        for(int j=row_start;j<row_end;j++) {\n",
    "          unsigned int Acol=cols[j];\n",
    "          double Acoef=Acoefs[j];\n",
    "          double xcoef=xcoefs[Acol];\n",
    "          sum+=Acoef*xcoef;\n",
    "        }\n",
    "        ycoefs[i]=sum;\n",
    "      }\n",
    "\n",
    "#### Fortran\n",
    "    !$acc parallel loop private(tmpsum,row_start,row_end) &\n",
    "    !$acc& present(arow_offsets,acols,acoefs,x,y)         &\n",
    "    !$acc& device_type(nvidia) gang worker num_workers(32) vector_length(32)\n",
    "    do i=1,a%num_rows\n",
    "      tmpsum = 0.0d0\n",
    "      row_start = arow_offsets(i)\n",
    "      row_end   = arow_offsets(i+1)-1\n",
    "      !$acc loop reduction(+:tmpsum) device_type(nvidia) vector\n",
    "      do j=row_start,row_end\n",
    "        acol = acols(j)\n",
    "        acoef = acoefs(j)\n",
    "        xcoef = x(acol)\n",
    "        tmpsum = tmpsum + acoef*xcoef\n",
    "      enddo\n",
    "      y(i) = tmpsum\n",
    "    enddo\n",
    "\n",
    "---\n",
    "\n",
    "After experimenting with the number of workers, performance should be \n",
    "similar to the table below.\n",
    "\n",
    "| Workers |\t  K40    |  Qwiklab  |\n",
    "|---------|----------|-----------|\n",
    "|    1    |          | 23.818328 |\n",
    "|    2    | 61.03544 | 13.19415  |\n",
    "|    4    | 31.36616 | 8.834735  |\n",
    "|    8    | 16.71916 | 9.030089  |\n",
    "|   16    | 8.81069  | 9.464214  |\n",
    "|   32    | 6.488389 | 10.400797 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab we started with a code that relied on CUDA Unified Memory to handle\n",
    "data movement and added explicit OpenACC data locality directives. This makes\n",
    "the code portable to any OpenACC compiler and accelerators that may not have\n",
    "Unified Memory. We used both the unstructured data directives and the `update`\n",
    "directive to achieve this.\n",
    "\n",
    "Next we profiled the code to determine how it could run more efficiently on the\n",
    "GPU we're using. We used our knowledge of both the application and the hardware\n",
    "to find a loop mapping that ran well on the GPU, achieving a 2-4X speed-up over\n",
    "our starting code.\n",
    "\n",
    "The table below shows runtime for each step of this lab on an NVIDIA Tesla K40 \n",
    "and on the Qwiklabs GPUs.\n",
    "\n",
    "| Step             | K40       | Qwiklab GPU | \n",
    "| ---------------- | --------- | ----------- |\n",
    "| Unified Memory   | 8.458172  | 32.084347   |\n",
    "| Explicit Memory  | 8.459754  | 33.251878   | \n",
    "| Vector Length 32 | 11.656281 | 23.83046    |\n",
    "| Final Code       | 4.802727  | 8.834735    | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Lab Summary\n",
    "\n",
    "If you would like to download this lab for later viewing, it is recommend you go to your browsers File menu (not the Jupyter notebook file menu) and save the complete web page.  This will ensure the images are copied down as well.\n",
    "\n",
    "You can also execute the following cell block to create a zip-file of the files you've been working on, and download it with the link below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f openacc_files.zip\n",
    "zip -r openacc_files.zip ~/c99/* ~/f90/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After** executing the above zip command, you should be able to download the zip file [here](files/openacc_files.zip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
